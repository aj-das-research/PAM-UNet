# ğŸ”¬ PAM-UNet: Progressive Attention Mobile UNet for Medical Image Segmentation

This repository contains the implementation of PAM-UNet, a novel architecture for medical image segmentation that combines mobile convolutions with a Progressive Luong Attention mechanism. ğŸ§ ğŸ’»

![PAM-UNet Architecture](./assets/pamunet_architecture.png)

## âœ¨ Features

- ğŸš€ Lightweight architecture using mobile convolutions
- ğŸ” Progressive Luong Attention for improved feature selection
- ğŸ¥ Efficient segmentation of medical images
- ğŸ“Š Support for various medical imaging datasets

## ğŸ› ï¸ Installation

1. Clone this repository:
   ```
   git clone https://github.com/yourusername/pam-unet.git
   cd pam-unet
   ```

2. Create a virtual environment and activate it:
   ```
   python -m venv venv
   source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
   ```

3. Install the required packages:
   ```
   pip install -r requirements.txt
   ```

## ğŸš€ Usage

### ğŸ“ Data Preparation

Place your dataset in the `data/` directory, organized as follows:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ masks/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ masks/
â””â”€â”€ test/
    â”œâ”€â”€ images/
    â””â”€â”€ masks/
```

### ğŸ‹ï¸â€â™€ï¸ Training

To train the PAM-UNet model, run:

```
python src/train.py
```

You can modify hyperparameters in the `train.py` script.

### ğŸ“Š Evaluation

To evaluate the trained model on the test set, run:

```
python src/evaluate.py
```

### ğŸ‘ï¸ Visualization

To visualize model predictions, run:

```
python src/visualize.py
```

## ğŸ“ˆ Results

Our PAM-UNet model achieves state-of-the-art performance on various medical image segmentation tasks. Here are some sample results:

![Sample Results](./assets/pamunet_results.png)

Performance metrics on benchmark datasets:

| Dataset | Dice Score | mIoU | Recall |
|---------|------------|------|--------|
| LiTS    | 82.87%     | 74.65%| 92.14% |
| Kvasir-SEG | 84.8%   | 78.40%| 86.63% |

## ğŸ“š Citation

If you use this code in your research, please cite our paper:

```
@article{das2024pam,
  title={PAM-UNet: Shifting Attention on Region of Interest in Medical Images},
  author={Das, Abhijit and Jha, Debesh and Gorade, Vandan and Biswas, Koushik and Pan, Hongyi and Zhang, Zheyuan and Ladner, Daniela P and Velichko, Yury and Borhani, Amir and Bagci, Ulas},
  journal={arXiv e-prints},
  pages={arXiv--2405},
  year={2024}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Thanks to the authors of UNet and MobileNet for their foundational work
- Gratitude to the LiTS and Kvasir-SEG dataset creators for providing benchmark data

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.